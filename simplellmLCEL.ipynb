{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Simple LLM Application with LCEL\n",
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "After seeing this video, you'll have a high level overview of:\n",
    "\n",
    "- Using language models\n",
    "\n",
    "- Using PromptTemplates and OutputParsers\n",
    "\n",
    "- Using LangChain Expression Language (LCEL) to chain components together\n",
    "\n",
    "- Debugging and tracing your application using LangSmith\n",
    "\n",
    "- Deploying your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Open AI API Key and Open Source models--Llama3,Gemma2,mistral--Groq\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#import openai   ___ this one is for openai api if we are using openai\n",
    "#openai.api_key=os.getenv(\"OPENAI_API_KEY\") ___ this one is for openai api if we are using openai\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000024817DF5550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000024817DF70E0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI \n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_core ___ this one is used for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **way one**\n",
    "\n",
    "**Here we will put everythig manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"Answer the questions and address me as BOSS and answer all the questions in Bangla!!\"), # This message will say how the model should work\n",
    "    HumanMessage(content=\"who are you and what you can do for me?\")\n",
    "]\n",
    "\n",
    "result=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='নমস্কার BOSS! আমি Gemma, একটি বৃহৎ ভাষা মডেল। Google DeepMind তৈরি করেছে। \\n\\nআমি আপনার জন্য অনেক কিছু করতে পারি, যেমন:\\n\\n* **প্রশ্নের উত্তর দিতে:** প্রায় যেকোন প্রশ্নের উত্তর দিতে পারব যা আমাকে শেখানো হয়েছে। \\n* **সাহিত্য সৃষ্টি করতে:** কবিতা, গল্প, নাটক, ইত্যাদি সৃষ্টি করতে পারি। \\n* **একাধিক ভাষায় অনূদিত করতে:** বিভিন্ন ভাষায় অনূদান করতে পারি। \\n* **সংক্ষিপ্ত এবং সারাংশ তৈরি করতে:** দীর্ঘ লেখার সংক্ষিপ্ত এবং সারাংশ তৈরি করতে পারি। \\n* **বিতর্কিত বিষয় নিয়ে আলোচনা করতে:** বিভিন্ন দৃষ্টিকোণ থেকে বিষয় নিয়ে আলোচনা করতে পারি। \\n\\n\\nআপনার কিছু কাজ আছে? BOSS, আমি আপনার অর্ডার পূরণ করার জন্য উন্নত। \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 315, 'prompt_tokens': 37, 'total_tokens': 352, 'completion_time': 0.572727273, 'prompt_time': 0.000305459, 'queue_time': 0.017883807999999998, 'total_time': 0.573032732}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-40466da9-8e50-4475-bd52-e09c53931eb5-0', usage_metadata={'input_tokens': 37, 'output_tokens': 315, 'total_tokens': 352})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Greetings, BOSS! \\n\\nI am Gemma, an open-weights AI assistant. I'm here to help you with a variety of tasks, such as:\\n\\n* **Generating creative content:** I can write stories, poems, articles, and even code.\\n* **Answering your questions:** I have been trained on a massive dataset of text and code, so I can provide you with information on a wide range of topics.\\n* **Summarizing text:** Need to get the gist of a long document? I can do that for you.\\n* **Translating languages:** \\n\\nWhile I primarily communicate in English, I have some ability to translate between other languages.\\n\\n* **And much more!**\\n\\nJust tell me what you need, BOSS, and I'll do my best to assist you.  What can I do for you today?\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "# Importing StrOutputParser from LangChain's core library.\n",
    "# This parser is designed to handle and process string-based outputs\n",
    "# efficiently, ensuring consistency and reusability in parsing logic.\n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Using the parser to process the 'result' variable.\n",
    "# Ideal for standardizing and extracting meaningful information\n",
    "# from raw string outputs returned by models or functions.\n",
    "parser.invoke(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Greetings, BOSS! \\n\\nI am Gemma, an AI assistant developed by the Gemma team at Google DeepMind.  \\n\\nI'm here to help you with a variety of tasks, such as:\\n\\n* **Generating creative content:**  Need a poem, a story idea, or help brainstorming? I can help!\\n* **Answering your questions:** I have access to a vast store of knowledge and can provide information on a wide range of topics.\\n* **Summarizing text:**  Give me a long article and I can condense it into the key points.\\n* **Translating languages:**  I can translate text between many different languages.\\n* **And much more!** I'm constantly learning and improving, so my abilities are always expanding.\\n\\nJust tell me what you need, BOSS, and I'll do my best to assist you.  What can I do for you today? \\n\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL- chain the components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Way Tow(Prompt Templates)**\n",
    "\n",
    "**Here we will define and structure everything using Prompt Templates manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template=\"Trnaslate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"Bangla\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Trnaslate the following into Bangla:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##Chaining together components with LCEL\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chain\u001b[38;5;241m=\u001b[39mprompt\u001b[38;5;241m|\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m|\u001b[39mparser\n\u001b[0;32m      3\u001b[0m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBangla\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "##Chaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"Bangla\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3.13 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
